{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "487b4bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kagglehub in /home/tr3p0l3m/tr3venv/lib/python3.10/site-packages (0.3.13)\n",
      "Requirement already satisfied: pyyaml in /home/tr3p0l3m/tr3venv/lib/python3.10/site-packages (from kagglehub) (6.0.2)\n",
      "Requirement already satisfied: tqdm in /home/tr3p0l3m/tr3venv/lib/python3.10/site-packages (from kagglehub) (4.67.1)\n",
      "Requirement already satisfied: requests in /home/tr3p0l3m/tr3venv/lib/python3.10/site-packages (from kagglehub) (2.32.3)\n",
      "Requirement already satisfied: packaging in /home/tr3p0l3m/tr3venv/lib/python3.10/site-packages (from kagglehub) (24.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/tr3p0l3m/tr3venv/lib/python3.10/site-packages (from requests->kagglehub) (2025.1.31)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/tr3p0l3m/tr3venv/lib/python3.10/site-packages (from requests->kagglehub) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/tr3p0l3m/tr3venv/lib/python3.10/site-packages (from requests->kagglehub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/tr3p0l3m/tr3venv/lib/python3.10/site-packages (from requests->kagglehub) (2.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: ipywidgets in /home/tr3p0l3m/tr3venv/lib/python3.10/site-packages (8.1.8)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/tr3p0l3m/tr3venv/lib/python3.10/site-packages (from ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in /home/tr3p0l3m/tr3venv/lib/python3.10/site-packages (from ipywidgets) (4.0.15)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/tr3p0l3m/tr3venv/lib/python3.10/site-packages (from ipywidgets) (8.37.0)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /home/tr3p0l3m/tr3venv/lib/python3.10/site-packages (from ipywidgets) (3.0.16)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/tr3p0l3m/tr3venv/lib/python3.10/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/tr3p0l3m/tr3venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in /home/tr3p0l3m/tr3venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.12.2)\n",
      "Requirement already satisfied: exceptiongroup in /home/tr3p0l3m/tr3venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (1.3.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /home/tr3p0l3m/tr3venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/tr3p0l3m/tr3venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: decorator in /home/tr3p0l3m/tr3venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/tr3p0l3m/tr3venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /home/tr3p0l3m/tr3venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: stack_data in /home/tr3p0l3m/tr3venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /home/tr3p0l3m/tr3venv/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.5)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/tr3p0l3m/tr3venv/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/tr3p0l3m/tr3venv/lib/python3.10/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.14)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/tr3p0l3m/tr3venv/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: pure-eval in /home/tr3p0l3m/tr3venv/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/tr3p0l3m/tr3venv/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install kagglehub\n",
    "%pip install ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408694a6",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21f7e668",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "from pathlib import Path\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4701fc02",
   "metadata": {},
   "source": [
    "### Download datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91b38b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_dataset(path):\n",
    "\tdest = Path(\"datasets\")\n",
    "\tdest.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\tsrc = Path(path)\n",
    "\tfor entry in src.iterdir():\n",
    "\t\ttarget = dest / entry.name\n",
    "\t\tif entry.is_dir():\n",
    "\t\t\tshutil.copytree(entry, target, dirs_exist_ok=True)\n",
    "\t\telse:\n",
    "\t\t\tshutil.copy2(entry, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8b8f37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/tr3p0l3m/.cache/kagglehub/datasets/yasserhessein/multiclass-diabetes-dataset/versions/1\n"
     ]
    }
   ],
   "source": [
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"yasserhessein/multiclass-diabetes-dataset\")\n",
    "\n",
    "download_dataset(path)\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5270d247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/tr3p0l3m/.cache/kagglehub/datasets/alexteboul/diabetes-health-indicators-dataset/versions/1\n"
     ]
    }
   ],
   "source": [
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"alexteboul/diabetes-health-indicators-dataset\")\n",
    "\n",
    "download_dataset(path)\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "300f84ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/tr3p0l3m/.cache/kagglehub/datasets/ishandutta/early-stage-diabetes-risk-prediction-dataset/versions/1\n"
     ]
    }
   ],
   "source": [
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\n",
    "    \"ishandutta/early-stage-diabetes-risk-prediction-dataset\"\n",
    ")\n",
    "\n",
    "download_dataset(path)\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdcc59d",
   "metadata": {},
   "source": [
    "### Dataset selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee3912f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2c11c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Multiclass Diabetes Dataset\n",
      "2. Dataset of Diabetes .csv\n",
      "3. Multiclass Diabetes Dataset.csv\n",
      "4. diabetes_012_health_indicators_BRFSS2015.csv\n",
      "5. diabetes_binary_5050split_health_indicators_BRFSS2015.csv\n",
      "6. diabetes_binary_health_indicators_BRFSS2015.csv\n",
      "7. diabetes_data_upload.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4fb231b96e948eca8ff25716482ab37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Dataset:', options=(('Multiclass Diabetes Dataset', PosixPath('datasets/Multiclass Diabeâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a113f01c7b242f19974806ca5033511",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "\tfrom IPython.display import display  # type: ignore\n",
    "\timport ipywidgets as widgets\n",
    "except Exception:\n",
    "\tdisplay = None\n",
    "\twidgets = None\n",
    "\n",
    "\n",
    "def list_available_datasets(dataset_root: Path) -> list[Path]:\n",
    "\tdataset_root = Path(dataset_root)\n",
    "\tif not dataset_root.exists():\n",
    "\t\traise ValueError(f\"No datasets found under {dataset_root.resolve()}\")\n",
    "\tdirectories = sorted(path for path in dataset_root.iterdir() if path.is_dir())\n",
    "\tcsv_files = sorted(path for path in dataset_root.iterdir() if path.is_file() and path.suffix.lower() == \".csv\")\n",
    "\tdataset_paths = directories + csv_files\n",
    "\tif not dataset_paths:\n",
    "\t\traise ValueError(f\"No datasets found under {dataset_root.resolve()}\")\n",
    "\tfor index, dataset_path in enumerate(dataset_paths, start=1):\n",
    "\t\tprint(f\"{index}. {dataset_path.name}\")\n",
    "\treturn dataset_paths\n",
    "\n",
    "\n",
    "def select_dataset_by_number(datasets: list[Path], selection: int | None = None) -> Path:\n",
    "\tif not datasets:\n",
    "\t\traise ValueError(\"No datasets available to select from.\")\n",
    "\tif selection is None:\n",
    "\t\tif len(datasets) == 1:\n",
    "\t\t\treturn datasets[0]\n",
    "\t\traise ValueError(\"Multiple datasets available. Please provide a selection.\")\n",
    "\tif not 1 <= selection <= len(datasets):\n",
    "\t\traise ValueError(f\"Selection {selection} is out of range 1..{len(datasets)}.\")\n",
    "\treturn datasets[selection - 1]\n",
    "\n",
    "\n",
    "def list_csv_files(dataset_path: Path, *, silent: bool = False) -> list[Path]:\n",
    "\tdataset_path = Path(dataset_path)\n",
    "\tif dataset_path.is_file():\n",
    "\t\tif dataset_path.suffix.lower() != \".csv\":\n",
    "\t\t\traise FileNotFoundError(f\"No CSV files found in {dataset_path.resolve()}\")\n",
    "\t\tif not silent:\n",
    "\t\t\tprint(dataset_path.name)\n",
    "\t\treturn [dataset_path]\n",
    "\tif not dataset_path.is_dir():\n",
    "\t\traise FileNotFoundError(f\"No CSV files found in {dataset_path.resolve()}\")\n",
    "\tcsv_files = sorted(dataset_path.rglob(\"*.csv\"))\n",
    "\tif not csv_files:\n",
    "\t\traise FileNotFoundError(f\"No CSV files found in {dataset_path.resolve()}\")\n",
    "\tif not silent:\n",
    "\t\tfor csv_file in csv_files:\n",
    "\t\t\tprint(csv_file.relative_to(dataset_path))\n",
    "\treturn csv_files\n",
    "\n",
    "\n",
    "def _in_notebook() -> bool:\n",
    "\ttry:\n",
    "\t\tfrom IPython import get_ipython\n",
    "\t\tip = get_ipython()\n",
    "\texcept Exception:\n",
    "\t\treturn False\n",
    "\tif ip is None:\n",
    "\t\treturn False\n",
    "\treturn \"IPKernelApp\" in getattr(ip, \"config\", {})\n",
    "\n",
    "\n",
    "def prompt_dataset_selection(datasets: list[Path]) -> Path:\n",
    "\tif len(datasets) == 1:\n",
    "\t\treturn datasets[0]\n",
    "\twhile True:\n",
    "\t\tselection_input = input(f\"Select dataset by number (1-{len(datasets)}) [default 1]: \").strip()\n",
    "\t\tif not selection_input:\n",
    "\t\t\treturn datasets[0]\n",
    "\t\tif selection_input.isdigit():\n",
    "\t\t\ttry:\n",
    "\t\t\t\treturn select_dataset_by_number(datasets, int(selection_input))\n",
    "\t\t\texcept ValueError as exc:\n",
    "\t\t\t\tprint(exc)\n",
    "\t\t\t\tcontinue\n",
    "\t\tprint(\"Please enter a valid integer.\")\n",
    "\n",
    "\n",
    "dataset_root = Path(\"datasets\")\n",
    "\n",
    "available_datasets = list_available_datasets(dataset_root)\n",
    "\n",
    "use_widgets = display is not None and widgets is not None and _in_notebook()\n",
    "\n",
    "if use_widgets:\n",
    "\tselector = widgets.Dropdown(\n",
    "\t\toptions=[(path.name, path) for path in available_datasets],\n",
    "\t\tdescription=\"Dataset:\",\n",
    "\t\tvalue=available_datasets[0],\n",
    "\t)\n",
    "\n",
    "\toutput = widgets.Output()\n",
    "\n",
    "\tdef update_selection(dataset_path: Path) -> None:\n",
    "\t\tglobal selected_dataset, csv_files\n",
    "\t\tselected_dataset = dataset_path\n",
    "\t\tcsv_files = list_csv_files(selected_dataset, silent=True)\n",
    "\t\toutput.clear_output()\n",
    "\t\twith output:\n",
    "\t\t\tprint(f\"Selected dataset: {selected_dataset}\")\n",
    "\t\t\tif selected_dataset.is_file():\n",
    "\t\t\t\tprint(selected_dataset.name)\n",
    "\t\t\telse:\n",
    "\t\t\t\tfor csv_file in csv_files:\n",
    "\t\t\t\t\tprint(csv_file.relative_to(selected_dataset))\n",
    "\n",
    "\tupdate_selection(selector.value)\n",
    "\n",
    "\tdef on_dataset_change(change: dict) -> None:\n",
    "\t\tif change[\"name\"] == \"value\" and change[\"new\"]:\n",
    "\t\t\tupdate_selection(change[\"new\"])\n",
    "\n",
    "\tselector.observe(on_dataset_change, names=\"value\")\n",
    "\n",
    "\tdisplay(selector, output)\n",
    "else:\n",
    "\tselected_dataset = prompt_dataset_selection(available_datasets)\n",
    "\tprint(f\"Selected dataset: {selected_dataset}\")\n",
    "\tcsv_files = list_csv_files(selected_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693917c2",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9918fd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Dataset of Diabetes .csv with 1000 rows and 14 columns. Target: class. Numeric features: 12. Categorical features: 1.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "df_raw = pd.read_csv(csv_files[0])\n",
    "df = df_raw.copy()\n",
    "df.columns = (\n",
    "\tdf.columns.str.strip()\n",
    "\t.str.lower()\n",
    "\t.str.replace(r\"[^0-9a-z]+\", \"_\", regex=True)\n",
    "\t.str.strip(\"_\")\n",
    ")\n",
    "\n",
    "df = df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "target_candidates = [\n",
    "\tcol for col in df.columns if col.lower() in {\"class\", \"outcome\", \"diabetes\", \"diabetes_binary\", \"diabetes_status\"}\n",
    "]\n",
    "target_column = target_candidates[0] if target_candidates else df.columns[-1]\n",
    "feature_columns = [col for col in df.columns if col != target_column]\n",
    "\n",
    "X = df[feature_columns].copy()\n",
    "y = df[target_column]\n",
    "\n",
    "categorical_columns = X.select_dtypes(exclude=\"number\").columns.tolist()\n",
    "numeric_columns = X.select_dtypes(include=\"number\").columns.tolist()\n",
    "\n",
    "if categorical_columns:\n",
    "\tX[categorical_columns] = (\n",
    "\t\tX[categorical_columns]\n",
    "\t\t.apply(lambda col: col.astype(str).str.strip())\n",
    "\t\t.replace({\"\": pd.NA})\n",
    "\t)\n",
    "\n",
    "one_hot_kwargs: dict[str, object] = {\"handle_unknown\": \"ignore\"}\n",
    "if \"sparse_output\" in OneHotEncoder.__init__.__code__.co_varnames:\n",
    "\tone_hot_kwargs[\"sparse_output\"] = False\n",
    "else:\n",
    "\tone_hot_kwargs[\"sparse\"] = False\n",
    "\n",
    "numeric_pipeline = Pipeline(steps=[(\"imputer\", SimpleImputer(strategy=\"median\"))])\n",
    "categorical_pipeline = Pipeline(\n",
    "\tsteps=[\n",
    "\t\t(\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "\t\t(\"encoder\", OneHotEncoder(**one_hot_kwargs)),\n",
    "\t]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "\ttransformers=[\n",
    "\t\t(\"num\", numeric_pipeline, numeric_columns),\n",
    "\t\t(\"cat\", categorical_pipeline, categorical_columns),\n",
    "\t],\n",
    "\tremainder=\"drop\",\n",
    ")\n",
    "\n",
    "X_preprocessed_array = preprocessor.fit_transform(X)\n",
    "feature_names = preprocessor.get_feature_names_out()\n",
    "X_preprocessed = pd.DataFrame(X_preprocessed_array, columns=feature_names, index=df.index)\n",
    "\n",
    "print(\n",
    "\tf\"Loaded {selected_dataset.name} with {df.shape[0]} rows and {df.shape[1]} columns. \"\n",
    "\tf\"Target: {target_column}. Numeric features: {len(numeric_columns)}. \"\n",
    "\tf\"Categorical features: {len(categorical_columns)}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cfc279",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6ddb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def engineer_features(features: pd.DataFrame) -> pd.DataFrame:\n",
    "\tengineered = features.copy()\n",
    "\n",
    "\thdl_safe = engineered[\"hdl\"].replace(0, np.nan)\n",
    "\tcr_safe = engineered[\"cr\"].replace(0, np.nan)\n",
    "\tchol_safe = engineered[\"chol\"].replace(0, np.nan)\n",
    "\n",
    "\tengineered[\"chol_hdl_ratio\"] = engineered[\"chol\"] / hdl_safe\n",
    "\tengineered[\"ldl_hdl_ratio\"] = engineered[\"ldl\"] / hdl_safe\n",
    "\tengineered[\"tg_hdl_ratio\"] = engineered[\"tg\"] / hdl_safe\n",
    "\tengineered[\"urea_creatinine_ratio\"] = engineered[\"urea\"] / cr_safe\n",
    "\tengineered[\"age_bmi_interaction\"] = engineered[\"age\"] * engineered[\"bmi\"]\n",
    "\tengineered[\"metabolic_score\"] = (\n",
    "\t\tengineered[[\"hba1c\", \"chol\", \"tg\", \"bmi\"]].rank(pct=True).mean(axis=1)\n",
    "\t)\n",
    "\tengineered[\"lipid_density\"] = (engineered[\"ldl\"] + engineered[\"vldl\"]) / chol_safe\n",
    "\tengineered[\"is_obese\"] = (engineered[\"bmi\"] >= 30).astype(int)\n",
    "\n",
    "\tage_band = pd.cut(\n",
    "\t\tengineered[\"age\"],\n",
    "\t\tbins=[0, 29, 39, 49, 59, 69, np.inf],\n",
    "\t\tlabels=[\"<30\", \"30-39\", \"40-49\", \"50-59\", \"60-69\", \"70+\"],\n",
    "\t\tright=True,\n",
    "\t\tinclude_lowest=True,\n",
    "\t)\n",
    "\tengineered[\"age_band\"] = age_band.astype(\"string\")\n",
    "\n",
    "\tratio_cols = [\n",
    "\t\t\"chol_hdl_ratio\",\n",
    "\t\t\"ldl_hdl_ratio\",\n",
    "\t\t\"tg_hdl_ratio\",\n",
    "\t\t\"urea_creatinine_ratio\",\n",
    "\t\t\"lipid_density\",\n",
    "\t]\n",
    "\tengineered[ratio_cols] = engineered[ratio_cols].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "\treturn engineered\n",
    "\n",
    "base_feature_columns = feature_columns.copy()\n",
    "X = engineer_features(X)\n",
    "new_feature_names = sorted(set(X.columns) - set(base_feature_columns))\n",
    "\n",
    "categorical_columns = X.select_dtypes(exclude=\"number\").columns.tolist()\n",
    "numeric_columns = X.select_dtypes(include=\"number\").columns.tolist()\n",
    "feature_columns = X.columns.tolist()\n",
    "\n",
    "numeric_pipeline = Pipeline(steps=[(\"imputer\", SimpleImputer(strategy=\"median\"))])\n",
    "categorical_pipeline = Pipeline(\n",
    "\tsteps=[\n",
    "\t\t(\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "\t\t(\"encoder\", OneHotEncoder(**one_hot_kwargs)),\n",
    "\t]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "\ttransformers=[\n",
    "\t\t(\"num\", numeric_pipeline, numeric_columns),\n",
    "\t\t(\"cat\", categorical_pipeline, categorical_columns),\n",
    "\t],\n",
    "\tremainder=\"drop\",\n",
    ")\n",
    "\n",
    "X_preprocessed_array = preprocessor.fit_transform(X)\n",
    "feature_names = preprocessor.get_feature_names_out()\n",
    "X_preprocessed = pd.DataFrame(X_preprocessed_array, columns=feature_names, index=df.index)\n",
    "\n",
    "print(\n",
    "\tf\"Engineered {len(new_feature_names)} new features; \"\n",
    "\tf\"{len(numeric_columns)} numeric and {len(categorical_columns)} categorical columns after transformation.\"\n",
    ")\n",
    "if new_feature_names:\n",
    "\tprint(\"New features:\", \", \".join(new_feature_names))\n",
    "print(f\"Preprocessed design matrix shape: {X_preprocessed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e0892e",
   "metadata": {},
   "source": [
    "### Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420f9576",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8852f9d",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4356019e",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
